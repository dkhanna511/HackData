{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical, normalize \n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/train/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/testpicture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img_chutiya(img):\n",
    "    word_label = img[0]\n",
    "  \n",
    "    if word_label == 'h': return 0\n",
    "    \n",
    "    elif word_label == 'b': return 1\n",
    "    elif word_label == 'v': return 2\n",
    "    elif word_label == 'l': return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(train_dir))\n",
    "for img in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir,img)\n",
    "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    #img_array=cv2.imread(img)  #converting the photo to greyscale\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    #break    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sizes of all the photos are different. \n",
    "# changing the size of every photo to a constant size to work for CNN\n",
    "\n",
    "img_size= 100\n",
    "\n",
    "new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "#plt.imshow(new_images)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for img in os.listdir(train_dir):\n",
    "        #try:\n",
    "        label = label_img_chutiya(img)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img=cv2.imread(path, cv2.IMREAD_COLOR)  \n",
    "        new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "        training_data.append([new_images, label])\n",
    "        #print(class_num)\n",
    "        #except Exception as e:\n",
    "         #   pass\n",
    "\n",
    "create_training_data()      \n",
    "#print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "def create_test_data():\n",
    "    \n",
    "    for img in (os.listdir(test_dir)):\n",
    "        label = label_image(img)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        #img_num = img.split('.')[0]\n",
    "        \n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), np.array(label)])\n",
    "    #np.save(\"testing_data.npy\", testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 100, 100, 3)\n",
      "[1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in training_data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "#plt.imshow(x[0])\n",
    "\n",
    "\n",
    "#converting the pixels into a numpy array\n",
    "#-1 for including all the images\n",
    "# img_size for the image size that we have taken\n",
    "# 1 since the image has been taken in a grayscale format\n",
    "x=np.array(x).reshape([-1, img_size, img_size, 3])\n",
    "print(x.shape)\n",
    "y=to_categorical(y,4)\n",
    "y=np.array(y)\n",
    "print(y[1000])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising the data by dividing it by the maximum value of pixel\n",
    "\n",
    "x=x/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 400 samples\n",
      "Epoch 1/3\n",
      "3600/3600 [==============================] - 153s 43ms/step - loss: 0.6853 - acc: 0.7172 - val_loss: 0.4037 - val_acc: 0.8750\n",
      "Epoch 2/3\n",
      "3600/3600 [==============================] - 119s 33ms/step - loss: 0.2402 - acc: 0.9142 - val_loss: 0.2168 - val_acc: 0.9100\n",
      "Epoch 3/3\n",
      "3600/3600 [==============================] - 121s 34ms/step - loss: 0.1158 - acc: 0.9581 - val_loss: 0.1191 - val_acc: 0.9525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Since the model is Sequential\n",
    "model=Sequential()\n",
    "\n",
    "\n",
    "#First Convolutional Layer\n",
    "\n",
    "#convolving the input layer with a 3*3 filter \n",
    "model.add(Conv2D(64, (3,3), input_shape=x.shape[1:]))\n",
    "\n",
    "#after Convolution, we can either pass activation function of Maxpooling\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second Convoutional Layer\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#Adding the fully connected Layer\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#Adding the output Layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x, y, batch_size=32,epochs=3, validation_split=0.1)\n",
    "y1=model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999940e-01 2.3731104e-12 1.1031426e-15 5.4457746e-07]\n",
      " [2.4730864e-03 9.8766220e-01 1.8596678e-03 8.0050966e-03]\n",
      " [9.9969876e-01 2.0134950e-04 2.0292974e-07 9.9648132e-05]\n",
      " ...\n",
      " [4.8701921e-03 9.8310626e-01 9.6955607e-03 2.3280086e-03]\n",
      " [3.4752098e-04 1.2319527e-02 4.4986606e-04 9.8688310e-01]\n",
      " [3.6728215e-10 1.7082196e-04 9.9982733e-01 1.9409272e-06]]\n",
      "(4000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y1)\n",
    "print(y1.shape)\n",
    "#print(to_categorical(y1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TOCO failed see console for info.\nb\"python: tpp.c:84: __pthread_tpp_change_priority: Assertion `new_prio == -1 || (new_prio >= fifo_min_prio && new_prio <= fifo_max_prio)' failed.\\nAborted (core dumped)\\n\"\nNone\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b87f68925e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converted_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m       \u001b[0;31m# Graphs without valid tensors cannot be loaded into tf.Session since they\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    341\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    343\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/contrib/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       raise RuntimeError(\"TOCO failed see console for info.\\n%s\\n%s\\n\" %\n\u001b[0;32m--> 135\u001b[0;31m                          (stdout, stderr))\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TOCO failed see console for info.\nb\"python: tpp.c:84: __pthread_tpp_change_priority: Assertion `new_prio == -1 || (new_prio >= fifo_min_prio && new_prio <= fifo_max_prio)' failed.\\nAborted (core dumped)\\n\"\nNone\n"
     ]
    }
   ],
   "source": [
    "keras_file = \"keras_model.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "# Convert to TensorFlow Lite model.\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''output_names = [node.op.name for node in model.outputs]\n",
    "sess = tf.keras.backend.get_session()\n",
    "frozen_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess, sess.graph_def, output_names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def apply_mask(matrix, mask, fill_value):\n",
    "\n",
    "    #print(flat[60])\n",
    "    #print(flat[11940])\n",
    "        \n",
    "    masked = np.ma.array(matrix, mask=mask, fill_value=fill_value)\n",
    "    #print('MASKED=',masked)\n",
    "    return masked.filled()\n",
    "\n",
    "def apply_threshold(matrix, low_value, high_value):\n",
    "    low_mask = matrix < low_value\n",
    "    matrix = apply_mask(matrix, low_mask, low_value)\n",
    "    #print('Low MASK->',low_mask,'\\nMatrix->',matrix)\n",
    "\n",
    "    high_mask = matrix > high_value\n",
    "    matrix = apply_mask(matrix, high_mask, high_value)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def simplest_cb(img, percent):\n",
    "    assert img.shape[2] == 3\n",
    "    assert percent > 0 and percent < 100\n",
    "\n",
    "    half_percent = percent / 200.0\n",
    "    #print('HALF PERCENT->',half_percent)\n",
    "\n",
    "    channels = cv2.split(img)\n",
    "    #print('Channels->\\n',channels)\n",
    "    #print('Shape->',channels[0].shape)\n",
    "    #print('Shape of channels->',len(channels[2]))\n",
    "\n",
    "    out_channels = []\n",
    "    for channel in channels:\n",
    "        assert len(channel.shape) == 2\n",
    "        # find the low and high precentile values (based on the input percentile)\n",
    "        height, width = channel.shape\n",
    "        vec_size = width * height\n",
    "        flat = channel.reshape(vec_size)\n",
    "        #print('vec=',vec_size,'\\nFlat=',flat)\n",
    "        assert len(flat.shape) == 1\n",
    "\n",
    "        flat = np.sort(flat)\n",
    "\n",
    "        n_cols = flat.shape[0]\n",
    "\n",
    "        low_val  = flat[math.floor(n_cols * half_percent)]\n",
    "        high_val = flat[math.ceil( n_cols * (1.0 - half_percent))]\n",
    "\n",
    "        #print (\"Lowval: \", low_val)\n",
    "        #print (\"Highval: \", high_val)\n",
    "\n",
    "        # saturate below the low percentile and above the high percentile\n",
    "        thresholded = apply_threshold(channel, low_val, high_val)\n",
    "        # scale the channel\n",
    "        normalized = cv2.normalize(thresholded, thresholded.copy(), 0, 255, cv2.NORM_MINMAX)\n",
    "        out_channels.append(normalized)\n",
    "\n",
    "    return cv2.merge(out_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory= \n",
      "\n",
      "\n",
      "\n",
      " ['', 'media', 'dheeraj', '9A26F0CB26F0AA01', 'WORK', 'jupyter_files', 'PlantDiseaseDetection', 'testpicture']\n",
      "The crop is suffering from :Vitaceae\n",
      "\n",
      "Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Vitaceae\n",
      "\n",
      "Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Bromaliaceae\n",
      "\n",
      "Remedy:Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Vitaceae\n",
      "\n",
      "Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Bromaliaceae\n",
      "\n",
      "Remedy:Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Bromaliaceae\n",
      "\n",
      "Remedy:Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Vitaceae\n",
      "\n",
      "Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n",
      "Thecurrent status of the crop is: Healthy \n",
      "\n",
      "No further action needed.\n",
      "The crop is suffering from :Vitaceae\n",
      "\n",
      "Discard or destroy any affected plants. \n",
      "  Do not compost them. \n",
      "  Rotate yoour tomato plants yearly to prevent re-infection next year. \n",
      " Use copper fungicites\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy\n",
    "files = os.listdir(test_dir)\n",
    "filepaths = [os.path.join(test_dir,i) for i in files]\n",
    "#print(filepaths)\n",
    "print(\"Directory= \\n\\n\\n\\n\", test_dir.split('/'))\n",
    "for i in filepaths:\n",
    "    img = cv2.imread(i)\n",
    "    try:\n",
    "        img.shape[2] == 3\n",
    "    except:\n",
    "        continue\n",
    "    out = simplest_cb(img, 1)\n",
    "    cv2.imshow(\"Before\", img)\n",
    "    cv2.imshow(\"After\", out)\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.waitKey(0)\n",
    "    #cv2.destoyAllwindows()\n",
    "        \n",
    "    \n",
    "    out=np.array(out)\n",
    "    out=cv2.resize(out, (img_size,img_size))\n",
    "    out=np.array(out).reshape([-1, img_size, img_size, 3])\n",
    "    y1=model.predict(out)\n",
    "    #print(y1)\n",
    "\n",
    "    for i in y1:\n",
    "        if i[0]==1:\n",
    "            print(\"Thecurrent status of the crop is: Healthy \\n\\nNo further action needed.\")\n",
    "        elif(i[1]==3):\n",
    "            print(\"The crop is suffering from :Lisianthus\\n\\nRemedy:Monitor the field, handpick diseased plants and bury them. \\n  Use sticky yellow plastic traps. \\n  Spray insecticides such as organophosphates, carbametes during the seedliing stage. \\n Use copper fungicites\")\n",
    "        elif(i[2]==1):\n",
    "            print(\"The crop is suffering from :Bromaliaceae\\n\\nRemedy:Discard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "        else:\n",
    "            print(\"The crop is suffering from :Vitaceae\\n\\nDiscard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
