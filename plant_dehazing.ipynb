{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical, normalize \n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/train/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/testpicture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img_chutiya(img):\n",
    "    word_label = img[0]\n",
    "  \n",
    "    if word_label == 'h': return 0\n",
    "    \n",
    "    elif word_label == 'b': return 1\n",
    "    elif word_label == 'v': return 2\n",
    "    elif word_label == 'l': return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(train_dir))\n",
    "for img in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir,img)\n",
    "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    #img_array=cv2.imread(img)  #converting the photo to greyscale\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    #break    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sizes of all the photos are different. \n",
    "# changing the size of every photo to a constant size to work for CNN\n",
    "\n",
    "img_size= 100\n",
    "\n",
    "new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "#plt.imshow(new_images)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for img in os.listdir(train_dir):\n",
    "        #try:\n",
    "        label = label_img_chutiya(img)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img=cv2.imread(path, cv2.IMREAD_COLOR)  \n",
    "        new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "        training_data.append([new_images, label])\n",
    "        #print(class_num)\n",
    "        #except Exception as e:\n",
    "         #   pass\n",
    "\n",
    "create_training_data()      \n",
    "#print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "def create_test_data():\n",
    "    \n",
    "    for img in (os.listdir(test_dir)):\n",
    "        label = label_image(img)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        #img_num = img.split('.')[0]\n",
    "        \n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), np.array(label)])\n",
    "    #np.save(\"testing_data.npy\", testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 100, 100, 3)\n",
      "[0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in training_data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "#plt.imshow(x[0])\n",
    "\n",
    "\n",
    "#converting the pixels into a numpy array\n",
    "#-1 for including all the images\n",
    "# img_size for the image size that we have taken\n",
    "# 1 since the image has been taken in a grayscale format\n",
    "x=np.array(x).reshape([-1, img_size, img_size, 3])\n",
    "print(x.shape)\n",
    "y=to_categorical(y,4)\n",
    "y=np.array(y)\n",
    "print(y[1000])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising the data by dividing it by the maximum value of pixel\n",
    "\n",
    "x=x/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 400 samples\n",
      "Epoch 1/3\n",
      "3600/3600 [==============================] - 141s 39ms/step - loss: 0.6975 - acc: 0.7014 - val_loss: 0.2801 - val_acc: 0.8950\n",
      "Epoch 2/3\n",
      "3600/3600 [==============================] - 145s 40ms/step - loss: 0.2680 - acc: 0.9047 - val_loss: 0.3042 - val_acc: 0.8800\n",
      "Epoch 3/3\n",
      "3600/3600 [==============================] - 152s 42ms/step - loss: 0.1627 - acc: 0.9431 - val_loss: 0.1852 - val_acc: 0.9200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Since the model is Sequential\n",
    "model=Sequential()\n",
    "\n",
    "\n",
    "#First Convolutional Layer\n",
    "\n",
    "#convolving the input layer with a 3*3 filter \n",
    "model.add(Conv2D(64, (3,3), input_shape=x.shape[1:]))\n",
    "\n",
    "#after Convolution, we can either pass activation function of Maxpooling\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second Convoutional Layer\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#Adding the fully connected Layer\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#Adding the output Layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x, y, batch_size=32,epochs=3, validation_split=0.1)\n",
    "y1=model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0567595e-04 8.0498832e-01 1.8823144e-01 6.6745868e-03]\n",
      " [9.8149008e-01 1.5598596e-02 8.7642245e-04 2.0348732e-03]\n",
      " [2.0633517e-03 9.9040133e-01 3.6859405e-03 3.8494426e-03]\n",
      " ...\n",
      " [2.5906721e-03 9.9120343e-01 3.9216182e-03 2.2842397e-03]\n",
      " [2.2565104e-02 9.7060150e-01 4.8249471e-03 2.0084390e-03]\n",
      " [8.0198003e-04 4.5070833e-01 1.6689773e-01 3.8159195e-01]]\n",
      "(4000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y1)\n",
    "print(y1.shape)\n",
    "#print(to_categorical(y1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheeraj/.local/lib/python3.5/site-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8825424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_file = \"keras_model.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "# Convert to TensorFlow Lite model.\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''output_names = [node.op.name for node in model.outputs]\n",
    "sess = tf.keras.backend.get_session()\n",
    "frozen_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess, sess.graph_def, output_names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def apply_mask(matrix, mask, fill_value):\n",
    "\n",
    "    #print(flat[60])\n",
    "    #print(flat[11940])\n",
    "        \n",
    "    masked = np.ma.array(matrix, mask=mask, fill_value=fill_value)\n",
    "    #print('MASKED=',masked)\n",
    "    return masked.filled()\n",
    "\n",
    "def apply_threshold(matrix, low_value, high_value):\n",
    "    low_mask = matrix < low_value\n",
    "    matrix = apply_mask(matrix, low_mask, low_value)\n",
    "    #print('Low MASK->',low_mask,'\\nMatrix->',matrix)\n",
    "\n",
    "    high_mask = matrix > high_value\n",
    "    matrix = apply_mask(matrix, high_mask, high_value)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def simplest_cb(img, percent):\n",
    "    assert img.shape[2] == 3\n",
    "    assert percent > 0 and percent < 100\n",
    "\n",
    "    half_percent = percent / 200.0\n",
    "    #print('HALF PERCENT->',half_percent)\n",
    "\n",
    "    channels = cv2.split(img)\n",
    "    #print('Channels->\\n',channels)\n",
    "    #print('Shape->',channels[0].shape)\n",
    "    #print('Shape of channels->',len(channels[2]))\n",
    "\n",
    "    out_channels = []\n",
    "    for channel in channels:\n",
    "        assert len(channel.shape) == 2\n",
    "        # find the low and high precentile values (based on the input percentile)\n",
    "        height, width = channel.shape\n",
    "        vec_size = width * height\n",
    "        flat = channel.reshape(vec_size)\n",
    "        #print('vec=',vec_size,'\\nFlat=',flat)\n",
    "        assert len(flat.shape) == 1\n",
    "\n",
    "        flat = np.sort(flat)\n",
    "\n",
    "        n_cols = flat.shape[0]\n",
    "\n",
    "        low_val  = flat[math.floor(n_cols * half_percent)]\n",
    "        high_val = flat[math.ceil( n_cols * (1.0 - half_percent))]\n",
    "\n",
    "        #print (\"Lowval: \", low_val)\n",
    "        #print (\"Highval: \", high_val)\n",
    "\n",
    "        # saturate below the low percentile and above the high percentile\n",
    "        thresholded = apply_threshold(channel, low_val, high_val)\n",
    "        # scale the channel\n",
    "        normalized = cv2.normalize(thresholded, thresholded.copy(), 0, 255, cv2.NORM_MINMAX)\n",
    "        out_channels.append(normalized)\n",
    "\n",
    "    return cv2.merge(out_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory= \n",
      "\n",
      "\n",
      "\n",
      " ['', 'media', 'dheeraj', '9A26F0CB26F0AA01', 'WORK', 'jupyter_files', 'PlantDiseaseDetection', 'testpicture']\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "PruneForTargets: Some target nodes not found: group_deps_1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4f45b2bfac1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0my1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print(y1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1878\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m         session != self._session):\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2926\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: PruneForTargets: Some target nodes not found: group_deps_1 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy\n",
    "files = os.listdir(test_dir)\n",
    "filepaths = [os.path.join(test_dir,i) for i in files]\n",
    "#print(filepaths)\n",
    "print(\"Directory= \\n\\n\\n\\n\", test_dir.split('/'))\n",
    "for i in filepaths:\n",
    "    img = cv2.imread(i)\n",
    "    try:\n",
    "        img.shape[2] == 3\n",
    "    except:\n",
    "        continue\n",
    "    out = simplest_cb(img, 1)\n",
    "    cv2.imshow(\"Before\", img)\n",
    "    cv2.imshow(\"After\", out)\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.waitKey(0)\n",
    "    #cv2.destoyAllwindows()\n",
    "        \n",
    "    \n",
    "    out=np.array(out)\n",
    "    out=cv2.resize(out, (img_size,img_size))\n",
    "    out=np.array(out).reshape([-1, img_size, img_size, 3])\n",
    "    y1=model.predict(out)\n",
    "    #print(y1)\n",
    "\n",
    "    for i in y1:\n",
    "        if i[0]==1:\n",
    "            print(\"Thecurrent status of the crop is: Healthy \\n\\nNo further action needed.\")\n",
    "        elif(i[1]==3):\n",
    "            print(\"The crop is suffering from :Lisianthus\\n\\nRemedy:Monitor the field, handpick diseased plants and bury them. \\n  Use sticky yellow plastic traps. \\n  Spray insecticides such as organophosphates, carbametes during the seedliing stage. \\n Use copper fungicites\")\n",
    "        elif(i[2]==1):\n",
    "            print(\"The crop is suffering from :Bromaliaceae\\n\\nRemedy:Discard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "        else:\n",
    "            print(\"The crop is suffering from :Vitaceae\\n\\nDiscard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
