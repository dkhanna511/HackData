{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical, normalize \n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/train/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=\"/media/dheeraj/9A26F0CB26F0AA01/WORK/jupyter_files/PlantDiseaseDetection/testpicture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img_chutiya(img):\n",
    "    word_label = img[0]\n",
    "  \n",
    "    if word_label == 'h': return 0\n",
    "    \n",
    "    elif word_label == 'b': return 1\n",
    "    elif word_label == 'v': return 2\n",
    "    elif word_label == 'l': return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(os.listdir(train_dir))\n",
    "for img in os.listdir(train_dir):\n",
    "    path = os.path.join(train_dir,img)\n",
    "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    #img_array=cv2.imread(img)  #converting the photo to greyscale\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    #break    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sizes of all the photos are different. \n",
    "# changing the size of every photo to a constant size to work for CNN\n",
    "\n",
    "img_size= 100\n",
    "\n",
    "new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "#plt.imshow(new_images)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for img in os.listdir(train_dir):\n",
    "        #try:\n",
    "        label = label_img_chutiya(img)\n",
    "        path = os.path.join(train_dir,img)\n",
    "        img=cv2.imread(path, cv2.IMREAD_COLOR)  \n",
    "        new_images=cv2.resize(img, (img_size, img_size))  # size of image is 100*100\n",
    "        training_data.append([new_images, label])\n",
    "        #print(class_num)\n",
    "        #except Exception as e:\n",
    "         #   pass\n",
    "\n",
    "create_training_data()      \n",
    "#print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "def create_test_data():\n",
    "    \n",
    "    for img in (os.listdir(test_dir)):\n",
    "        label = label_image(img)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        #img_num = img.split('.')[0]\n",
    "        \n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), np.array(label)])\n",
    "    #np.save(\"testing_data.npy\", testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 100, 100, 3)\n",
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in training_data:\n",
    "    x.append(features)\n",
    "    y.append(labels)\n",
    "#plt.imshow(x[0])\n",
    "\n",
    "\n",
    "#converting the pixels into a numpy array\n",
    "#-1 for including all the images\n",
    "# img_size for the image size that we have taken\n",
    "# 1 since the image has been taken in a grayscale format\n",
    "x=np.array(x).reshape([-1, img_size, img_size, 3])\n",
    "print(x.shape)\n",
    "y=to_categorical(y,4)\n",
    "y=np.array(y)\n",
    "print(y[1000])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising the data by dividing it by the maximum value of pixel\n",
    "\n",
    "x=x/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 400 samples\n",
      "Epoch 1/3\n",
      "3600/3600 [==============================] - 138s 38ms/step - loss: 0.7013 - acc: 0.7156 - val_loss: 0.4865 - val_acc: 0.8275\n",
      "Epoch 2/3\n",
      "3600/3600 [==============================] - 142s 39ms/step - loss: 0.2149 - acc: 0.9256 - val_loss: 0.1871 - val_acc: 0.9400\n",
      "Epoch 3/3\n",
      "2816/3600 [======================>.......] - ETA: 29s - loss: 0.1456 - acc: 0.9489"
     ]
    }
   ],
   "source": [
    "\n",
    "#Since the model is Sequential\n",
    "model=Sequential()\n",
    "\n",
    "\n",
    "#First Convolutional Layer\n",
    "\n",
    "#convolving the input layer with a 3*3 filter \n",
    "model.add(Conv2D(64, (3,3), input_shape=x.shape[1:]))\n",
    "\n",
    "#after Convolution, we can either pass activation function of Maxpooling\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Second Convoutional Layer\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#Adding the fully connected Layer\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#Adding the output Layer\n",
    "model.add(Dense(4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x, y, batch_size=32,epochs=3, validation_split=0.1)\n",
    "y1=model.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y1)\n",
    "print(y1.shape)\n",
    "#print(to_categorical(y1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file = \"keras_model.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)\n",
    "\n",
    "# Convert to TensorFlow Lite model.\n",
    "#converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''output_names = [node.op.name for node in model.outputs]\n",
    "sess = tf.keras.backend.get_session()\n",
    "frozen_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess, sess.graph_def, output_names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def apply_mask(matrix, mask, fill_value):\n",
    "\n",
    "    #print(flat[60])\n",
    "    #print(flat[11940])\n",
    "        \n",
    "    masked = np.ma.array(matrix, mask=mask, fill_value=fill_value)\n",
    "    #print('MASKED=',masked)\n",
    "    return masked.filled()\n",
    "\n",
    "def apply_threshold(matrix, low_value, high_value):\n",
    "    low_mask = matrix < low_value\n",
    "    matrix = apply_mask(matrix, low_mask, low_value)\n",
    "    #print('Low MASK->',low_mask,'\\nMatrix->',matrix)\n",
    "\n",
    "    high_mask = matrix > high_value\n",
    "    matrix = apply_mask(matrix, high_mask, high_value)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def simplest_cb(img, percent):\n",
    "    assert img.shape[2] == 3\n",
    "    assert percent > 0 and percent < 100\n",
    "\n",
    "    half_percent = percent / 200.0\n",
    "    #print('HALF PERCENT->',half_percent)\n",
    "\n",
    "    channels = cv2.split(img)\n",
    "    #print('Channels->\\n',channels)\n",
    "    #print('Shape->',channels[0].shape)\n",
    "    #print('Shape of channels->',len(channels[2]))\n",
    "\n",
    "    out_channels = []\n",
    "    for channel in channels:\n",
    "        assert len(channel.shape) == 2\n",
    "        # find the low and high precentile values (based on the input percentile)\n",
    "        height, width = channel.shape\n",
    "        vec_size = width * height\n",
    "        flat = channel.reshape(vec_size)\n",
    "        #print('vec=',vec_size,'\\nFlat=',flat)\n",
    "        assert len(flat.shape) == 1\n",
    "\n",
    "        flat = np.sort(flat)\n",
    "\n",
    "        n_cols = flat.shape[0]\n",
    "\n",
    "        low_val  = flat[math.floor(n_cols * half_percent)]\n",
    "        high_val = flat[math.ceil( n_cols * (1.0 - half_percent))]\n",
    "\n",
    "        #print (\"Lowval: \", low_val)\n",
    "        #print (\"Highval: \", high_val)\n",
    "\n",
    "        # saturate below the low percentile and above the high percentile\n",
    "        thresholded = apply_threshold(channel, low_val, high_val)\n",
    "        # scale the channel\n",
    "        normalized = cv2.normalize(thresholded, thresholded.copy(), 0, 255, cv2.NORM_MINMAX)\n",
    "        out_channels.append(normalized)\n",
    "\n",
    "    return cv2.merge(out_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy\n",
    "files = os.listdir(test_dir)\n",
    "filepaths = [os.path.join(test_dir,i) for i in files]\n",
    "#print(filepaths)\n",
    "print(\"Directory= \\n\\n\\n\\n\", test_dir.split('/'))\n",
    "for i in filepaths:\n",
    "    img = cv2.imread(i)\n",
    "    try:\n",
    "        img.shape[2] == 3\n",
    "    except:\n",
    "        continue\n",
    "    out = simplest_cb(img, 1)\n",
    "    cv2.imshow(\"Before\", img)\n",
    "    cv2.imshow(\"After\", out)\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.waitKey(0)\n",
    "    #cv2.destoyAllwindows()\n",
    "        \n",
    "    \n",
    "    out=np.array(out)\n",
    "    out=cv2.resize(out, (img_size,img_size))\n",
    "    out=np.array(out).reshape([-1, img_size, img_size, 3])\n",
    "    y1=model.predict(out)\n",
    "    #print(y1)\n",
    "\n",
    "    for i in y1:\n",
    "        if i[0]==1:\n",
    "            print(\"Thecurrent status of the crop is: Healthy \\n\\nNo further action needed.\")\n",
    "        elif(i[1]==3):\n",
    "            print(\"The crop is suffering from :Lisianthus\\n\\nRemedy:Monitor the field, handpick diseased plants and bury them. \\n  Use sticky yellow plastic traps. \\n  Spray insecticides such as organophosphates, carbametes during the seedliing stage. \\n Use copper fungicites\")\n",
    "        elif(i[2]==1):\n",
    "            print(\"The crop is suffering from :Bromaliaceae\\n\\nRemedy:Discard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "        else:\n",
    "            print(\"The crop is suffering from :Vitaceae\\n\\nDiscard or destroy any affected plants. \\n  Do not compost them. \\n  Rotate yoour tomato plants yearly to prevent re-infection next year. \\n Use copper fungicites\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
